{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yMs_hr88HCSX",
        "NRz3VRBqHGW-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## INTRO\n",
        "\n",
        "nro id : se não tiver length 16 adicionar 0 na frente\n",
        "\n",
        "instituição\n",
        "- hospital : não é de ensino, tem q marcar q não é de academia\n",
        "- mesma instituição, registros e tempos diferentes  =>  tem q agrupar\n",
        "similaridade de string -> função cosseno de PLN (ngramas)\n",
        "\n",
        "\n",
        "\n",
        "1) pegar o nome de todas as instituições do brasil (usar a lista do MEC)\n",
        "\n",
        "\n",
        "- fazer a tabela de frequência /\n",
        "eliminar oq tem pouca frequência\n",
        "- se for secretaria municipal algo assim e aparecer poucas vezes => só rotular como servidor público\n",
        "- se estiver so EACH (sem ter USP no nome), categorizar como 'outros'\n",
        "- lista de universidades\n",
        "    - tabela do ROR\n",
        "    - tabela do MEC"
      ],
      "metadata": {
        "id": "MTrrgTO6SP5l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00SstqcJMsXL"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir('/content/gdrive/My Drive/USP/2024_2º/MQA/')\n",
        "\n",
        "pd.set_option('display.max_rows', 6)\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## READ_CSV"
      ],
      "metadata": {
        "id": "DfWK_wpL93gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('atuacoes_2.csv', encoding='UTF-8', nrows=50) #, dtype=str, nrows=1000)\n",
        "\n",
        "df['ANO-FIM'] = df['ANO-FIM'].fillna(2024)\n",
        "df['FLAG-DEDICACAO-EXCLUSIVA'] = df['FLAG-DEDICACAO-EXCLUSIVA'].replace('NAO', False).replace('SIM', True)\n",
        "\n",
        "df = df.astype({\n",
        "    'NRO-ID-CNPQ': int,\n",
        "    'CODIGO-INSTITUICAO': str,\n",
        "    'NOME-INSTITUICAO': str,\n",
        "    'ANO-INICIO': int,\n",
        "    'ANO-FIM': int,\n",
        "    'ENQUADRAMENTO-FUNCIONAL': str,\n",
        "    'TIPO-DE-VINCULO': str,\n",
        "    'OUTRAS-INFORMACOES': str,\n",
        "    'CARGA-HORARIA-SEMANAL': float,\n",
        "    'FLAG-DEDICACAO-EXCLUSIVA': bool\n",
        "})\n",
        "\n",
        "df = df.fillna(' ')\n",
        "df2 = df.copy()\n",
        "\n",
        "#df"
      ],
      "metadata": {
        "id": "CFoGSIJUNa0V",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.copy(deep=True)\n",
        "df2.isna().sum()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "uyMYIGTi5Qh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LISTA DE IES NACIONAIS\n",
        "# https://dadosabertos.mec.gov.br/indicadores-sobre-ensino-superior/item/181-instituicoes-de-educacao-superior-do-brasil\n",
        "# https://dadosabertos.mec.gov.br/images/conteudo/Ind-ensino-superior/2022/PDA_Lista_Instituicoes_Ensino_Superior_do_Brasil_EMEC.csv\n",
        "\n",
        "df_uni = pd.read_csv('sup.csv', encoding='UTF-8')\n",
        "df_uni_filtered = df_uni[['NOME_DA_IES', 'SIGLA']]\n",
        "df_uni_filtered = df_uni_filtered.fillna('')\n",
        "df_uni_filtered = df_uni_filtered.sort_values(['NOME_DA_IES'], ascending=False)\n",
        "df_uni_filtered"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9DBxFuCNCvXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATA PREPROCESSING"
      ],
      "metadata": {
        "id": "ebnx3vUR97YU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_names(df, column_name):\n",
        "\n",
        "    # Remover NaN\n",
        "    #df.dropna(subset=[column_name])\n",
        "\n",
        "    # Remover '&'\n",
        "    df[column_name] = df[column_name].replace('&AMP;', ' ', regex=True)\n",
        "\n",
        "    # Remover todos os caracteres nao alfa-numericos, exceto whitespace\n",
        "    df[column_name] = df[column_name].str.replace('[^\\w\\s]', ' ', regex=True)\n",
        "\n",
        "    # Normalizar a string\n",
        "    df[column_name] = df[column_name].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
        "\n",
        "    # Remover stopwords\n",
        "    stop = ['DO', 'DA', 'DE', 'E']\n",
        "    df[column_name] = df[column_name].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "\n",
        "    # Strip whitespace\n",
        "    df[column_name] = df[column_name].apply(lambda x: x.strip())\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "m_7f_j8ItqUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de Curriculo Lattes\n",
        "\n",
        "# Tratar os nomes da NOME-INSTITUICAO\n",
        "df2 = df2.apply(lambda x: x.astype(str).str.upper())\n",
        "df2 = clean_names(df2, 'NOME-INSTITUICAO')\n",
        "\n",
        "# Dropar linhas com IES < 50\n",
        "#df2 = df2[df2.groupby('NOME-INSTITUICAO')['NOME-INSTITUICAO'].transform('count').ge(50)]\n",
        "\n",
        "# Split df: educacao & outros\n",
        "df2_edu = df2.loc[df2['ENQUADRAMENTO-FUNCIONAL'].isin(['LIVRE', 'COLABORADOR', 'PROFESSOR_VISITANTE'])].copy(deep=True)\n",
        "df2_outros = df2.loc[df2['ENQUADRAMENTO-FUNCIONAL'].isin(['SERVIDOR_PUBLICO', 'CELETISTA', 'NAN', 'OUTRO'])].copy(deep=True)\n",
        "\n",
        "df2_edu"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9aEDyAjASwo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df2_edu['NOME-INSTITUICAO'].isna().sum())\n",
        "print(df2_edu['NOME-INSTITUICAO'].value_counts())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "W6fxMsyE3ZHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de IES\n",
        "\n",
        "df_uni_filtered = df_uni_filtered.apply(lambda x: x.astype(str).str.upper())\n",
        "df_uni_filtered = clean_names(df_uni_filtered, 'NOME_DA_IES')\n",
        "\n",
        "# merge colunas NOME e SIGLA\n",
        "df_uni_filtered['NOME_E_SIGLA'] = df_uni_filtered['SIGLA'] + ' ' + df_uni_filtered['NOME_DA_IES']\n",
        "df_uni_filtered"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kBPNTDKHuyrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NLP\n"
      ],
      "metadata": {
        "id": "l4oFZp0WWw6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cosine"
      ],
      "metadata": {
        "id": "ZpUuXCDrW3II"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "threshold = 0.8\n",
        "\n",
        "# Vetorização TF-IDF\n",
        "vectorizer = TfidfVectorizer().fit(df_uni_filtered['NOME_DA_IES'])\n",
        "tfidf_matrix_universidades = vectorizer.transform(df_uni_filtered['NOME_DA_IES'])\n",
        "\n",
        "df2_edu['nome_corrigido'] = ''\n",
        "\n",
        "for index, row in df2_edu.iterrows():\n",
        "\n",
        "    nome_instituicao = row['NOME-INSTITUICAO']\n",
        "\n",
        "    vector_comparacao = vectorizer.transform([nome_instituicao])\n",
        "\n",
        "    similaridade = cosine_similarity(vector_comparacao, tfidf_matrix_universidades)\n",
        "\n",
        "    max_value = np.max(similaridade)\n",
        "    max_index = np.argmax(similaridade)\n",
        "\n",
        "    nome_corrigido = df_uni_filtered.iloc[max_index]['NOME_DA_IES']\n",
        "\n",
        "    if (max_value >= threshold):\n",
        "        df2_edu.at[index, 'nome_corrigido'] = nome_corrigido\n",
        "    else:\n",
        "        df2_edu.at[index, 'nome_corrigido'] = nome_instituicao"
      ],
      "metadata": {
        "collapsed": true,
        "id": "m2qr0ICWSl55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# oq foi alterado\n",
        "pd.set_option('display.max_rows', 10)\n",
        "print(df2_edu[['NOME-INSTITUICAO', 'nome_corrigido']].loc[df2_edu['NOME-INSTITUICAO'] != df2_edu['nome_corrigido']])\n",
        "pd.set_option('display.max_rows', 6)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WCzEPI5aOpco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SIMILARIDADE POR NOME E SIGLA\n",
        "# EM QUANTIDADE MAIOR DE AMOSTRA, NAO FUNCIONA MUITO BEM\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "threshold = 0.8\n",
        "\n",
        "vectorizer = TfidfVectorizer().fit(df_uni_filtered['NOME_E_SIGLA'])\n",
        "tfidf_matrix_universidades = vectorizer.transform(df_uni_filtered['NOME_E_SIGLA'])\n",
        "\n",
        "df2_edu['nome_corrigido'] = ''\n",
        "\n",
        "for index, row in df2_edu.iterrows():\n",
        "\n",
        "    nome_instituicao = row['NOME-INSTITUICAO']\n",
        "\n",
        "    vector_comparacao = vectorizer.transform([nome_instituicao])\n",
        "\n",
        "    similaridade = cosine_similarity(vector_comparacao, tfidf_matrix_universidades)\n",
        "\n",
        "    max_value = np.max(similaridade)\n",
        "    max_index = np.argmax(similaridade)\n",
        "\n",
        "    nome_corrigido = df_uni_filtered.iloc[max_index]['NOME_DA_IES']\n",
        "\n",
        "    if (max_value >= threshold):\n",
        "        df2_edu.at[index, 'nome_corrigido'] = nome_corrigido\n",
        "    else:\n",
        "        df2_edu.at[index, 'nome_corrigido'] = nome_instituicao"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TfiLw6NBLyZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cosine by N-gram\n"
      ],
      "metadata": {
        "id": "sAfGA8JlW5iB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "threshold = 0.6\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=(2, 3)).fit(df_uni_filtered['NOME_DA_IES'])\n",
        "tfidf_matrix_universidades = vectorizer.transform(df_uni_filtered['NOME_DA_IES'])\n",
        "\n",
        "df2_edu['nome_corrigido_ngram'] = ''\n",
        "\n",
        "for index, row in df2_edu.iterrows():\n",
        "    nome_instituicao = row['NOME-INSTITUICAO']\n",
        "\n",
        "    vector_comparacao = vectorizer.transform([nome_instituicao])\n",
        "\n",
        "    similaridade = cosine_similarity(vector_comparacao, tfidf_matrix_universidades)\n",
        "\n",
        "    max_value = np.max(similaridade)  # Valor máximo de similaridade\n",
        "    max_index = np.argmax(similaridade)  # Índice do valor máximo\n",
        "\n",
        "    nome_corrigido = df_uni_filtered.iloc[max_index]['NOME_DA_IES']\n",
        "\n",
        "    if max_value >= threshold:\n",
        "        df2_edu.at[index, 'nome_corrigido_ngram'] = nome_corrigido\n",
        "    else:\n",
        "        df2_edu.at[index, 'nome_corrigido_ngram'] = nome_instituicao"
      ],
      "metadata": {
        "collapsed": true,
        "id": "C-_PGB8kWrG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 100)\n",
        "print(df2_edu[['NOME-INSTITUICAO', 'nome_corrigido_ngram']].loc[df2_edu['NOME-INSTITUICAO'] != df2_edu['nome_corrigido_ngram']])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WiIvrUHJX3T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jaccard"
      ],
      "metadata": {
        "id": "aOXd1We6A8db"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def jaccard_similarity(str1, str2):\n",
        "\n",
        "    set1 = set(str1.split())\n",
        "    set2 = set(str2.split())\n",
        "\n",
        "    intersection = len(set1.intersection(set2))\n",
        "    union = len(set1.union(set2))\n",
        "\n",
        "    return intersection / union if union != 0 else 0\n",
        "\n",
        "threshold = 0.5\n",
        "\n",
        "df2_edu['nome_corrigido'] = ''\n",
        "\n",
        "for index, row in df2_edu.iterrows():\n",
        "\n",
        "    nome_instituicao = row['NOME-INSTITUICAO']\n",
        "    max_similarity = 0\n",
        "    nome_corrigido = nome_instituicao\n",
        "\n",
        "    # TODO: deixar a set previamente pronta\n",
        "    for idx_uni, row_uni in df_uni_filtered.iterrows():\n",
        "        nome_uni = row_uni['NOME_DA_IES']\n",
        "        similarity = jaccard_similarity(nome_instituicao, nome_uni)\n",
        "\n",
        "        if similarity > max_similarity:\n",
        "            max_similarity = similarity\n",
        "            nome_corrigido = nome_uni\n",
        "\n",
        "    if max_similarity >= threshold:\n",
        "        df2_edu.at[index, 'nome_corrigido'] = nome_corrigido\n",
        "    else:\n",
        "        df2_edu.at[index, 'nome_corrigido'] = nome_instituicao\n"
      ],
      "metadata": {
        "id": "p4f9hmYmBB6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# oq foi alterado\n",
        "pd.set_option('display.max_rows', 10)\n",
        "print(df2_edu[['NOME-INSTITUICAO', 'nome_corrigido']].loc[df2_edu['NOME-INSTITUICAO'] != df2_edu['nome_corrigido']])\n",
        "pd.set_option('display.max_rows', 6)"
      ],
      "metadata": {
        "id": "-mOWBzK8E-kD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Euclidean Distance"
      ],
      "metadata": {
        "id": "TWrudvSNFo-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "import numpy as np\n",
        "\n",
        "threshold = 0.8\n",
        "\n",
        "vectorizer = TfidfVectorizer().fit(df_uni_filtered['NOME_DA_IES'])\n",
        "tfidf_matrix_universidades = vectorizer.transform(df_uni_filtered['NOME_DA_IES'])\n",
        "\n",
        "df2_edu['nome_corrigido'] = ''\n",
        "\n",
        "for index, row in df2_edu.iterrows():\n",
        "    nome_instituicao = row['NOME-INSTITUICAO']\n",
        "\n",
        "    vector_comparacao = vectorizer.transform([nome_instituicao])\n",
        "\n",
        "    distancias = euclidean_distances(vector_comparacao, tfidf_matrix_universidades)\n",
        "\n",
        "    min_distancia = np.min(distancias)\n",
        "    min_index = np.argmin(distancias)\n",
        "\n",
        "    nome_corrigido = df_uni_filtered.iloc[min_index]['NOME_DA_IES']\n",
        "\n",
        "    if min_distancia <= threshold:\n",
        "        df2_edu.at[index, 'nome_corrigido'] = nome_corrigido\n",
        "    else:\n",
        "        df2_edu.at[index, 'nome_corrigido'] = nome_instituicao"
      ],
      "metadata": {
        "id": "DZmE8CKEF5c4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clustering: K-Means\n",
        "- ARRUMAR"
      ],
      "metadata": {
        "id": "YrDpB_ex5Jlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "vectorizer = TfidfVectorizer().fit(df_uni_filtered['NOME_E_SIGLA'].values)\n",
        "tfidf_matrix_1 = vectorizer.transform(df_uni_filtered['NOME_E_SIGLA'].values)\n",
        "\n",
        "n_clusters = 2754  # quantidade de IES existentes\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "kmeans.fit(tfidf_matrix_1)\n",
        "\n",
        "cluster_labels = kmeans.labels_\n",
        "\n",
        "for i in range(n_clusters):\n",
        "    cluster_points = np.where(cluster_labels == i)[0]\n",
        "    cluster_center = kmeans.cluster_centers_[i]\n",
        "\n",
        "    # Find document closest to the centroid (most recurring)\n",
        "    closest_doc_idx = np.argmax(cosine_similarity(tfidf_matrix_1[cluster_points], [cluster_center]))\n",
        "    most_recurring_idx = cluster_points[closest_doc_idx]\n",
        "    original_row_index = df2_edu.index[most_recurring_idx]\n",
        "    most_recurring_document = df2_edu.loc[original_row_index]\n",
        "    print(most_recurring_document['NOME-INSTITUICAO'])\n",
        "most_recurring_document"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IaYifA3s0h_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "vectorizer = TfidfVectorizer().fit(df_uni_filtered['NOME_DA_IES'])\n",
        "tfidf_matrix_universidades = vectorizer.transform(df_uni_filtered['NOME_DA_IES'])\n",
        "\n",
        "num_clusters = 4000 # qtd de IES\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42).fit(tfidf_matrix_universidades)\n",
        "clusters = kmeans.predict(tfidf_matrix_universidades)\n",
        "\n",
        "df_uni_filtered['cluster'] = clusters\n",
        "\n",
        "# Crie um dicionário para armazenar o nome mais representativo de cada cluster\n",
        "representative_names = {}\n",
        "for cluster in range(num_clusters):\n",
        "    cluster_names = df_uni_filtered[df_uni_filtered['cluster'] == cluster]['NOME_DA_IES']\n",
        "    # Escolha o nome mais frequente no cluster como representante\n",
        "    representative_names[cluster] = cluster_names.mode()[0]\n",
        "\n",
        "# Nova coluna\n",
        "df2_edu['nome_corrigido_kmeans'] = ''\n",
        "\n",
        "for index, row in df2_edu.iterrows():\n",
        "    nome_instituicao = row['NOME-INSTITUICAO']\n",
        "\n",
        "    vector_comparacao = vectorizer.transform([nome_instituicao])\n",
        "\n",
        "    # Prever o cluster para o nome da instituição\n",
        "    cluster_prediction = kmeans.predict(vector_comparacao)[0]\n",
        "\n",
        "    # Obter o nome mais representativo do cluster\n",
        "    nome_corrigido = representative_names.get(cluster_prediction, nome_instituicao)\n",
        "\n",
        "    df2_edu.at[index, 'nome_corrigido_kmeans'] = nome_corrigido\n",
        "\n",
        "    # print(f'{nome_instituicao} corrigido para {nome_corrigido}')\n"
      ],
      "metadata": {
        "id": "pISvOjMjZujh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 100)\n",
        "print(df2_edu[['NOME-INSTITUICAO', 'nome_corrigido_kmeans']].loc[df2_edu['NOME-INSTITUICAO'] != df2_edu['nome_corrigido_kmeans']])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "duh4DPdca89a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Embedding\n",
        "- ARRUMAR\n",
        "- muito lentooo\n",
        "- 50k linhas : 3min"
      ],
      "metadata": {
        "id": "S9NzgnRzZA2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_sm\n",
        "import spacy\n",
        "\n",
        "# AJUSTAR O CODIGO PQ NAO TROCA A COLUNA NEM NADA\n",
        "\n",
        "nlp = spacy.load(\"pt_core_news_sm\")  # Carrega um modelo pré-treinado\n",
        "df2['spacy_similarity'] = df2.apply(\n",
        "    lambda row: nlp(row['NOME-INSTITUICAO']).similarity(nlp(df_uni_filtered['NOME_DA_IES'][row['indice_mais_similar']])),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "df2"
      ],
      "metadata": {
        "id": "tOWcN-3YZDUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outras possibilidades:\n",
        "- Word2Vect\n",
        "- Modelos que levam em consideracao o sentido semantico"
      ],
      "metadata": {
        "id": "TYcdvOaacBIE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1g0BU_brcDQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MERGE SAME UNI"
      ],
      "metadata": {
        "id": "yMs_hr88HCSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# merge ANO-INICIO e ANO-FIM com mesmo CODIGO-INSTITUICAO e NRO-ID-CNPQ\n",
        "\n",
        "df_merged = df.groupby(['NRO-ID-CNPQ', 'CODIGO-INSTITUICAO']).agg(\n",
        "    earliest_date1=('ANO-INICIO', 'min'),\n",
        "    latest_date2=('ANO-FIM', 'max')\n",
        ").reset_index()\n",
        "\n",
        "\n",
        "# df.loc[df['NRO-ID-CNPQ'] == 3300778291054405]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2UILjKN8ivGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge colunas NOME-INSTITUICAO com df_merged\n",
        "\n",
        "df_drop_duplicates = df.drop_duplicates(subset=['NRO-ID-CNPQ', 'CODIGO-INSTITUICAO'])\n",
        "df_inst_merged = pd.merge(df_merged, df_drop_duplicates, on=['CODIGO-INSTITUICAO', 'NRO-ID-CNPQ'], how='left')\n",
        "df_inst_merged['NOME-INSTITUICAO'] = df_inst_merged['NOME-INSTITUICAO'].str.upper()\n",
        "\n",
        "df_inst_merged = df_inst_merged[['NRO-ID-CNPQ', 'CODIGO-INSTITUICAO', 'earliest_date1', 'latest_date2', 'NOME-INSTITUICAO']]\n",
        "df_inst_merged"
      ],
      "metadata": {
        "id": "XG2dRH1glZ6A",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXPORT TO CSV"
      ],
      "metadata": {
        "id": "NRz3VRBqHGW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_inst_merged.to_csv(\"atuacoes_2_filtrado.csv\", encoding='utf8')"
      ],
      "metadata": {
        "id": "QJ74QOglqEBH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}